{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Character-Level LSTM in PyTorch.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "authorship_tag": "ABX9TyMI4GRivhy36e4zXt1ZifN2"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "construct a character-level LSTM with PyTorch. The network will train character by character on some text, then generate new text character by character. As an example, I will train on Anna Karenina. **This model will be able to generate new text based on the text from the book!**\n"
   ],
   "metadata": {
    "id": "gu-ODf4nDbCY",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#Import Libraries"
   ],
   "metadata": {
    "id": "__rEjG7oDoaq",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "OlBTX3FMDUbV",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1658430642504,
     "user_tz": -120,
     "elapsed": 2305,
     "user": {
      "displayName": "Mohamed Ashraf",
      "userId": "01470115126079514692"
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load in Data\n"
   ],
   "metadata": {
    "id": "FU7vYcu_D2U0",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# open text file and read in data as text\n",
    "with open('text.txt','r') as f:\n",
    "  text = f.read()"
   ],
   "metadata": {
    "id": "Ti_vZg1fD4E8",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1658430644855,
     "user_tz": -120,
     "elapsed": 1274,
     "user": {
      "displayName": "Mohamed Ashraf",
      "userId": "01470115126079514692"
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "text[:100]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "9-zk6acvECwh",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1658430644856,
     "user_tz": -120,
     "elapsed": 29,
     "user": {
      "displayName": "Mohamed Ashraf",
      "userId": "01470115126079514692"
     }
    },
    "outputId": "a6544118-fa60-438f-b71a-ff30b2b68ef3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "'Chapter 1\\n\\n\\nHappy families are all alike; every unhappy family is unhappy in its own\\nway.\\n\\nEverythin'"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#Tokenization\n",
    "In the cells, below, I'm creating a couple dictionaries to convert the characters to and from integers. Encoding the characters as integers makes it easier to use as input in the network."
   ],
   "metadata": {
    "id": "CwFZaS43E6lW",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# we create two dictionaries:\n",
    "# 1. int2char, which maps integers to chars\n",
    "# 2. chat2int, which maps chars to integers\n",
    "\n",
    "chars = tuple(set(text))\n",
    "int2char = dict(enumerate(chars))\n",
    "char2int = {ch: ii for ii, ch in int2char.items()}\n",
    "\n",
    "# endcoed the text\n",
    "encoded = np.array([char2int[ch] for ch in text])"
   ],
   "metadata": {
    "id": "u9rBWBmZE3Wp",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1658430644857,
     "user_tz": -120,
     "elapsed": 28,
     "user": {
      "displayName": "Mohamed Ashraf",
      "userId": "01470115126079514692"
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "encoded[:100]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GrvsX9zfFEsf",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1658430644858,
     "user_tz": -120,
     "elapsed": 29,
     "user": {
      "displayName": "Mohamed Ashraf",
      "userId": "01470115126079514692"
     }
    },
    "outputId": "c8187b48-2aca-495b-e9d0-f7e2ad43a335",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "array([67, 41, 30, 52, 64, 37, 65, 73, 50, 81, 81, 81, 56, 30, 52, 52, 39,\n       73, 74, 30, 24, 44, 35, 44, 37, 36, 73, 30, 65, 37, 73, 30, 35, 35,\n       73, 30, 35, 44, 33, 37, 20, 73, 37, 13, 37, 65, 39, 73, 48, 68, 41,\n       30, 52, 52, 39, 73, 74, 30, 24, 44, 35, 39, 73, 44, 36, 73, 48, 68,\n       41, 30, 52, 52, 39, 73, 44, 68, 73, 44, 64, 36, 73, 62, 46, 68, 81,\n       46, 30, 39, 32, 81, 81, 31, 13, 37, 65, 39, 64, 41, 44, 68])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pre-processing the data"
   ],
   "metadata": {
    "id": "6tiF5OqvFxLD",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def one_hot_encode(arr, n_labels):\n",
    "  \n",
    "  # Initializing the encoded array\n",
    "  one_hot = np.zeros( (arr.size, n_labels), dtype = np.float32 )\n",
    "\n",
    "  # Fill the appropirate elements with ones\n",
    "  one_hot[np.arange(one_hot.shape[0]), arr.flatten()] = 1\n",
    "\n",
    "\n",
    "  one_hot = one_hot.reshape((*arr.shape, n_labels))\n",
    "\n",
    "  return one_hot\n"
   ],
   "metadata": {
    "id": "8_oemUtnFuCE",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1658430644858,
     "user_tz": -120,
     "elapsed": 27,
     "user": {
      "displayName": "Mohamed Ashraf",
      "userId": "01470115126079514692"
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "test_seq = np.array([[3,5,1]])\n",
    "one_hot = one_hot_encode(test_seq,8)\n",
    "\n",
    "print(one_hot)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7Y_5BRHYG2As",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1658430644859,
     "user_tz": -120,
     "elapsed": 27,
     "user": {
      "displayName": "Mohamed Ashraf",
      "userId": "01470115126079514692"
     }
    },
    "outputId": "e84f223d-cc14-4557-b0dc-3fdc4a00c2c2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0. 0. 0. 0. 0.]]]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Making training mini-batches\n"
   ],
   "metadata": {
    "id": "DtYMNS2CHgf8",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def get_batches(arr, batch_size , seq_length):\n",
    "\n",
    "  '''Create a generator that returns batches of size\n",
    "       batch_size x seq_length from arr.\n",
    "       \n",
    "       Arguments\n",
    "       ---------\n",
    "       arr: Array you want to make batches from\n",
    "       batch_size: Batch size, the number of sequences per batch\n",
    "       seq_length: Number of encoded chars in a sequence\n",
    "    '''\n",
    "  batch_size_total = batch_size * seq_length\n",
    "  # total number of batches we can make\n",
    "  n_batches = len(arr)//batch_size_total\n",
    "\n",
    "  # Keep only enough characters to make full batches\n",
    "  arr = arr[:n_batches * batch_size_total]\n",
    " \n",
    "  # Reshape into batch_size rows\n",
    "  arr = arr.reshape((batch_size,-1))\n",
    "\n",
    "  # iterate through the array, one sequence at a time\n",
    "  for n in range(0, arr.shape[1], seq_length):\n",
    "    \n",
    "    x = arr[:, n:n+seq_length]\n",
    "    # the targets, shifted by one\n",
    "    y = np.zeros_like(x)\n",
    "    try:\n",
    "      y[:, :-1], y[:, -1] = x[:, 1:], arr[:, n+seq_length]\n",
    "    except IndexError:\n",
    "      y[:, :-1], y[:, -1] = x[:, 1:], arr[:, 0]\n",
    "    yield x, y\n"
   ],
   "metadata": {
    "id": "c_k2c2BhHFcx",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1658430644859,
     "user_tz": -120,
     "elapsed": 26,
     "user": {
      "displayName": "Mohamed Ashraf",
      "userId": "01470115126079514692"
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test"
   ],
   "metadata": {
    "id": "pk02l8XaJe0j",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "batches = get_batches(encoded, 8, 50)\n",
    "x, y = next(batches)"
   ],
   "metadata": {
    "id": "dHz0foBzH0JJ",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1658430644860,
     "user_tz": -120,
     "elapsed": 26,
     "user": {
      "displayName": "Mohamed Ashraf",
      "userId": "01470115126079514692"
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# printing out the first 10 items in a sequence\n",
    "print('x\\n', x[:10, :10])\n",
    "print('\\ny\\n', y[:10, :10])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uROAkVKcJofq",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1658430644860,
     "user_tz": -120,
     "elapsed": 26,
     "user": {
      "displayName": "Mohamed Ashraf",
      "userId": "01470115126079514692"
     }
    },
    "outputId": "9801e51f-4b20-432f-e716-4543da6b8d43",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x\n",
      " [[67 41 30 52 64 37 65 73 50 81]\n",
      " [36 62 68 73 64 41 30 64 73 30]\n",
      " [37 68 71 73 62 65 73 30 73 74]\n",
      " [36 73 64 41 37 73 57 41 44 37]\n",
      " [73 36 30 46 73 41 37 65 73 64]\n",
      " [57 48 36 36 44 62 68 73 30 68]\n",
      " [73  8 68 68 30 73 41 30 71 73]\n",
      " [45 21 35 62 68 36 33 39 32 73]]\n",
      "\n",
      "y\n",
      " [[41 30 52 64 37 65 73 50 81 81]\n",
      " [62 68 73 64 41 30 64 73 30 64]\n",
      " [68 71 73 62 65 73 30 73 74 62]\n",
      " [73 64 41 37 73 57 41 44 37 74]\n",
      " [36 30 46 73 41 37 65 73 64 37]\n",
      " [48 36 36 44 62 68 73 30 68 71]\n",
      " [ 8 68 68 30 73 41 30 71 73 36]\n",
      " [21 35 62 68 36 33 39 32 73 17]]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Defining the network with PyTorch\n",
    "### Model Structure\n",
    "In __init__ the suggested structure is as follows:\n",
    "\n",
    "* Create and store the necessary dictionaries (this has been done for you)\n",
    "* Define an LSTM layer that takes as params: an input size (the number of characters), a hidden layer size n_hidden, a number of layers n_layers, a dropout probability drop_prob, and a batch_first boolean (True, since we are batching)\n",
    "* Define a dropout layer with drop_prob\n",
    "* Define a fully-connected layer with params: input size n_hidden and output size (the number of characters)\n",
    "* Finally, initialize the weights (again, this has been given)\n",
    "\n",
    "Note that some parameters have been named and given in the __init__ function, and we use them and store them by doing something like self.drop_prob = drop_prob.\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "X4T0n_04Jtc7",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# check if GPU is available\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "if(train_on_gpu):\n",
    "    print('Training on GPU!')\n",
    "else: \n",
    "    print('No GPU available, training on CPU; consider making n_epochs very small.')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BTnAI-D3JpTf",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1658430644861,
     "user_tz": -120,
     "elapsed": 26,
     "user": {
      "displayName": "Mohamed Ashraf",
      "userId": "01470115126079514692"
     }
    },
    "outputId": "19241c8e-e368-41e8-b0e0-9cdb18097acb",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on GPU!\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "class CharRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, tokens, n_hidden=256, n_layers=2,\n",
    "                               drop_prob=0.5, lr=0.001):\n",
    "        super().__init__()\n",
    "        self.drop_prob = drop_prob\n",
    "        self.n_layers = n_layers\n",
    "        self.n_hidden = n_hidden\n",
    "        self.lr = lr\n",
    "        \n",
    "        # creating character dictionaries\n",
    "        self.chars = tokens\n",
    "        self.int2char = dict(enumerate(self.chars))\n",
    "        self.char2int = {ch: ii for ii, ch in self.int2char.items()}\n",
    "        \n",
    "        # define the LSTM\n",
    "        self.lstm = nn.LSTM(len(self.chars), n_hidden, n_layers, \n",
    "                            dropout=drop_prob, batch_first=True)\n",
    "        \n",
    "        \n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        \n",
    "        # fully-connected output layer\n",
    "        self.fc = nn.Linear(n_hidden, len(self.chars))\n",
    "      \n",
    "    \n",
    "    def forward(self, x, hidden):\n",
    "        ''' Forward pass through the network. \n",
    "            These inputs are x, and the hidden/cell state `hidden`. '''\n",
    "                \n",
    "        # Get the outputs and the new hidden state from the lstm\n",
    "        r_output, hidden = self.lstm(x, hidden)\n",
    "        \n",
    "        # pass through a dropout layer\n",
    "        out = self.dropout(r_output)\n",
    "        \n",
    "        # Stack up LSTM outputs using view\n",
    "        # you may need to use contiguous to reshape the output\n",
    "        out = out.contiguous().view(-1, self.n_hidden)\n",
    "        \n",
    "        # put x through the fully-connected layer\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        # return the final output and the hidden state\n",
    "        return out, hidden\n",
    "    \n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        ''' Initializes hidden state '''\n",
    "        # Create two new tensors with sizes n_layers x batch_size x n_hidden,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "        \n",
    "        if (train_on_gpu):\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda(),\n",
    "                  weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda())\n",
    "        else:\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_(),\n",
    "                      weight.new(self.n_layers, batch_size, self.n_hidden).zero_())\n",
    "        \n",
    "        return hidden"
   ],
   "metadata": {
    "id": "PO6DuTFRKGxr",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1658430644861,
     "user_tz": -120,
     "elapsed": 24,
     "user": {
      "displayName": "Mohamed Ashraf",
      "userId": "01470115126079514692"
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train"
   ],
   "metadata": {
    "id": "cqdtQ4u7KI4j",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def train(net, data, epochs=10, batch_size=10, seq_length=50, lr=0.001, clip=5, val_frac=0.1, print_every=10):\n",
    "    ''' Training a network \n",
    "    \n",
    "        Arguments\n",
    "        ---------\n",
    "        \n",
    "        net: CharRNN network\n",
    "        data: text data to train the network\n",
    "        epochs: Number of epochs to train\n",
    "        batch_size: Number of mini-sequences per mini-batch, aka batch size\n",
    "        seq_length: Number of character steps per mini-batch\n",
    "        lr: learning rate\n",
    "        clip: gradient clipping\n",
    "        val_frac: Fraction of data to hold out for validation\n",
    "        print_every: Number of steps for printing training and validation loss\n",
    "    \n",
    "    '''\n",
    "    net.train()\n",
    "    \n",
    "    opt = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # create training and validation data\n",
    "    val_idx = int(len(data)*(1-val_frac))\n",
    "    data, val_data = data[:val_idx], data[val_idx:]\n",
    "    \n",
    "    if(train_on_gpu):\n",
    "        net.cuda()\n",
    "    \n",
    "    counter = 0\n",
    "    n_chars = len(net.chars)\n",
    "    for e in range(epochs):\n",
    "        # initialize hidden state\n",
    "        h = net.init_hidden(batch_size)\n",
    "        \n",
    "        for x, y in get_batches(data, batch_size, seq_length):\n",
    "            counter += 1\n",
    "            \n",
    "            # One-hot encode our data and make them Torch tensors\n",
    "            x = one_hot_encode(x, n_chars)\n",
    "            inputs, targets = torch.from_numpy(x), torch.from_numpy(y)\n",
    "            \n",
    "            if(train_on_gpu):\n",
    "                inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "            # Creating new variables for the hidden state, otherwise\n",
    "            # we'd backprop through the entire training history\n",
    "            h = tuple([each.data for each in h])\n",
    "\n",
    "            # zero accumulated gradients\n",
    "            net.zero_grad()\n",
    "            \n",
    "            # get the output from the model\n",
    "            output, h = net(inputs, h)\n",
    "            \n",
    "            # calculate the loss and perform backprop\n",
    "            loss = criterion(output, targets.view(batch_size*seq_length).long())\n",
    "            loss.backward()\n",
    "            # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "            nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
    "            opt.step()\n",
    "            \n",
    "            # loss stats\n",
    "            if counter % print_every == 0:\n",
    "                # Get validation loss\n",
    "                val_h = net.init_hidden(batch_size)\n",
    "                val_losses = []\n",
    "                net.eval()\n",
    "                for x, y in get_batches(val_data, batch_size, seq_length):\n",
    "                    # One-hot encode our data and make them Torch tensors\n",
    "                    x = one_hot_encode(x, n_chars)\n",
    "                    x, y = torch.from_numpy(x), torch.from_numpy(y)\n",
    "                    \n",
    "                    # Creating new variables for the hidden state, otherwise\n",
    "                    # we'd backprop through the entire training history\n",
    "                    val_h = tuple([each.data for each in val_h])\n",
    "                    \n",
    "                    inputs, targets = x, y\n",
    "                    if(train_on_gpu):\n",
    "                        inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "                    output, val_h = net(inputs, val_h)\n",
    "                    val_loss = criterion(output, targets.view(batch_size*seq_length).long())\n",
    "                \n",
    "                    val_losses.append(val_loss.item())\n",
    "                \n",
    "                net.train() # reset to train mode after iterationg through validation data\n",
    "                \n",
    "                print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "                      \"Step: {}...\".format(counter),\n",
    "                      \"Loss: {:.4f}...\".format(loss.item()),\n",
    "                      \"Val Loss: {:.4f}\".format(np.mean(val_losses)))"
   ],
   "metadata": {
    "id": "jFRl-V2sKLvz",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1658430644861,
     "user_tz": -120,
     "elapsed": 24,
     "user": {
      "displayName": "Mohamed Ashraf",
      "userId": "01470115126079514692"
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Instantiating the model\n",
    "Now we can actually train the network. First we'll create the network itself, with some given hyperparameters. Then, define the mini-batches sizes, and start training!"
   ],
   "metadata": {
    "id": "i_YNG5v0KVAr",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# define and print the net\n",
    "n_hidden=512\n",
    "n_layers=2\n",
    "\n",
    "net = CharRNN(chars, n_hidden, n_layers)\n",
    "print(net)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MBftEMQyKRJA",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1658430644862,
     "user_tz": -120,
     "elapsed": 25,
     "user": {
      "displayName": "Mohamed Ashraf",
      "userId": "01470115126079514692"
     }
    },
    "outputId": "90c6a843-f68a-4e39-c5fa-8f7a27f988c1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CharRNN(\n",
      "  (lstm): LSTM(83, 512, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc): Linear(in_features=512, out_features=83, bias=True)\n",
      ")\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "batch_size = 128\n",
    "seq_length = 100\n",
    "n_epochs = 20 # start smaller if you are just testing initial behavior\n",
    "\n",
    "# train the model\n",
    "train(net, encoded, epochs=n_epochs, batch_size=batch_size, seq_length=seq_length, lr=0.001, print_every=10)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eOn8QWT4KRIA",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1658431054862,
     "user_tz": -120,
     "elapsed": 410023,
     "user": {
      "displayName": "Mohamed Ashraf",
      "userId": "01470115126079514692"
     }
    },
    "outputId": "c5db28c4-2e0c-4120-ed2e-b58cb667c056",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/20... Step: 10... Loss: 3.2829... Val Loss: 3.2305\n",
      "Epoch: 1/20... Step: 20... Loss: 3.1553... Val Loss: 3.1431\n",
      "Epoch: 1/20... Step: 30... Loss: 3.1486... Val Loss: 3.1257\n",
      "Epoch: 1/20... Step: 40... Loss: 3.1162... Val Loss: 3.1197\n",
      "Epoch: 1/20... Step: 50... Loss: 3.1445... Val Loss: 3.1179\n",
      "Epoch: 1/20... Step: 60... Loss: 3.1175... Val Loss: 3.1161\n",
      "Epoch: 1/20... Step: 70... Loss: 3.1098... Val Loss: 3.1151\n",
      "Epoch: 1/20... Step: 80... Loss: 3.1239... Val Loss: 3.1124\n",
      "Epoch: 1/20... Step: 90... Loss: 3.1244... Val Loss: 3.1059\n",
      "Epoch: 1/20... Step: 100... Loss: 3.1019... Val Loss: 3.0927\n",
      "Epoch: 1/20... Step: 110... Loss: 3.0755... Val Loss: 3.0656\n",
      "Epoch: 1/20... Step: 120... Loss: 2.9909... Val Loss: 2.9899\n",
      "Epoch: 1/20... Step: 130... Loss: 2.9549... Val Loss: 2.9188\n",
      "Epoch: 2/20... Step: 140... Loss: 2.8210... Val Loss: 2.8135\n",
      "Epoch: 2/20... Step: 150... Loss: 2.7311... Val Loss: 2.6861\n",
      "Epoch: 2/20... Step: 160... Loss: 2.6219... Val Loss: 2.5829\n",
      "Epoch: 2/20... Step: 170... Loss: 2.5285... Val Loss: 2.5191\n",
      "Epoch: 2/20... Step: 180... Loss: 2.4996... Val Loss: 2.4753\n",
      "Epoch: 2/20... Step: 190... Loss: 2.4459... Val Loss: 2.4452\n",
      "Epoch: 2/20... Step: 200... Loss: 2.4321... Val Loss: 2.4031\n",
      "Epoch: 2/20... Step: 210... Loss: 2.4024... Val Loss: 2.3780\n",
      "Epoch: 2/20... Step: 220... Loss: 2.3566... Val Loss: 2.3409\n",
      "Epoch: 2/20... Step: 230... Loss: 2.3459... Val Loss: 2.3211\n",
      "Epoch: 2/20... Step: 240... Loss: 2.3397... Val Loss: 2.2996\n",
      "Epoch: 2/20... Step: 250... Loss: 2.2668... Val Loss: 2.2734\n",
      "Epoch: 2/20... Step: 260... Loss: 2.2378... Val Loss: 2.2368\n",
      "Epoch: 2/20... Step: 270... Loss: 2.2342... Val Loss: 2.2117\n",
      "Epoch: 3/20... Step: 280... Loss: 2.2309... Val Loss: 2.1877\n",
      "Epoch: 3/20... Step: 290... Loss: 2.1923... Val Loss: 2.1606\n",
      "Epoch: 3/20... Step: 300... Loss: 2.1730... Val Loss: 2.1414\n",
      "Epoch: 3/20... Step: 310... Loss: 2.1429... Val Loss: 2.1163\n",
      "Epoch: 3/20... Step: 320... Loss: 2.1031... Val Loss: 2.0926\n",
      "Epoch: 3/20... Step: 330... Loss: 2.0791... Val Loss: 2.0762\n",
      "Epoch: 3/20... Step: 340... Loss: 2.0977... Val Loss: 2.0579\n",
      "Epoch: 3/20... Step: 350... Loss: 2.0800... Val Loss: 2.0336\n",
      "Epoch: 3/20... Step: 360... Loss: 2.0056... Val Loss: 2.0191\n",
      "Epoch: 3/20... Step: 370... Loss: 2.0320... Val Loss: 1.9984\n",
      "Epoch: 3/20... Step: 380... Loss: 2.0072... Val Loss: 1.9858\n",
      "Epoch: 3/20... Step: 390... Loss: 1.9840... Val Loss: 1.9660\n",
      "Epoch: 3/20... Step: 400... Loss: 1.9476... Val Loss: 1.9504\n",
      "Epoch: 3/20... Step: 410... Loss: 1.9672... Val Loss: 1.9335\n",
      "Epoch: 4/20... Step: 420... Loss: 1.9518... Val Loss: 1.9174\n",
      "Epoch: 4/20... Step: 430... Loss: 1.9394... Val Loss: 1.9034\n",
      "Epoch: 4/20... Step: 440... Loss: 1.9188... Val Loss: 1.8972\n",
      "Epoch: 4/20... Step: 450... Loss: 1.8631... Val Loss: 1.8799\n",
      "Epoch: 4/20... Step: 460... Loss: 1.8586... Val Loss: 1.8697\n",
      "Epoch: 4/20... Step: 470... Loss: 1.8883... Val Loss: 1.8563\n",
      "Epoch: 4/20... Step: 480... Loss: 1.8676... Val Loss: 1.8435\n",
      "Epoch: 4/20... Step: 490... Loss: 1.8740... Val Loss: 1.8350\n",
      "Epoch: 4/20... Step: 500... Loss: 1.8625... Val Loss: 1.8205\n",
      "Epoch: 4/20... Step: 510... Loss: 1.8368... Val Loss: 1.8103\n",
      "Epoch: 4/20... Step: 520... Loss: 1.8492... Val Loss: 1.7974\n",
      "Epoch: 4/20... Step: 530... Loss: 1.8023... Val Loss: 1.7871\n",
      "Epoch: 4/20... Step: 540... Loss: 1.7677... Val Loss: 1.7778\n",
      "Epoch: 4/20... Step: 550... Loss: 1.8105... Val Loss: 1.7667\n",
      "Epoch: 5/20... Step: 560... Loss: 1.7754... Val Loss: 1.7557\n",
      "Epoch: 5/20... Step: 570... Loss: 1.7661... Val Loss: 1.7468\n",
      "Epoch: 5/20... Step: 580... Loss: 1.7457... Val Loss: 1.7382\n",
      "Epoch: 5/20... Step: 590... Loss: 1.7483... Val Loss: 1.7286\n",
      "Epoch: 5/20... Step: 600... Loss: 1.7369... Val Loss: 1.7217\n",
      "Epoch: 5/20... Step: 610... Loss: 1.7196... Val Loss: 1.7138\n",
      "Epoch: 5/20... Step: 620... Loss: 1.7211... Val Loss: 1.7123\n",
      "Epoch: 5/20... Step: 630... Loss: 1.7474... Val Loss: 1.7019\n",
      "Epoch: 5/20... Step: 640... Loss: 1.7021... Val Loss: 1.6944\n",
      "Epoch: 5/20... Step: 650... Loss: 1.6925... Val Loss: 1.6846\n",
      "Epoch: 5/20... Step: 660... Loss: 1.6701... Val Loss: 1.6780\n",
      "Epoch: 5/20... Step: 670... Loss: 1.6929... Val Loss: 1.6718\n",
      "Epoch: 5/20... Step: 680... Loss: 1.6950... Val Loss: 1.6638\n",
      "Epoch: 5/20... Step: 690... Loss: 1.6637... Val Loss: 1.6571\n",
      "Epoch: 6/20... Step: 700... Loss: 1.6738... Val Loss: 1.6513\n",
      "Epoch: 6/20... Step: 710... Loss: 1.6518... Val Loss: 1.6452\n",
      "Epoch: 6/20... Step: 720... Loss: 1.6431... Val Loss: 1.6360\n",
      "Epoch: 6/20... Step: 730... Loss: 1.6621... Val Loss: 1.6334\n",
      "Epoch: 6/20... Step: 740... Loss: 1.6256... Val Loss: 1.6267\n",
      "Epoch: 6/20... Step: 750... Loss: 1.6053... Val Loss: 1.6194\n",
      "Epoch: 6/20... Step: 760... Loss: 1.6415... Val Loss: 1.6170\n",
      "Epoch: 6/20... Step: 770... Loss: 1.6308... Val Loss: 1.6113\n",
      "Epoch: 6/20... Step: 780... Loss: 1.6096... Val Loss: 1.6052\n",
      "Epoch: 6/20... Step: 790... Loss: 1.5952... Val Loss: 1.5984\n",
      "Epoch: 6/20... Step: 800... Loss: 1.6085... Val Loss: 1.5944\n",
      "Epoch: 6/20... Step: 810... Loss: 1.5991... Val Loss: 1.5930\n",
      "Epoch: 6/20... Step: 820... Loss: 1.5622... Val Loss: 1.5877\n",
      "Epoch: 6/20... Step: 830... Loss: 1.6093... Val Loss: 1.5781\n",
      "Epoch: 7/20... Step: 840... Loss: 1.5672... Val Loss: 1.5710\n",
      "Epoch: 7/20... Step: 850... Loss: 1.5780... Val Loss: 1.5711\n",
      "Epoch: 7/20... Step: 860... Loss: 1.5650... Val Loss: 1.5619\n",
      "Epoch: 7/20... Step: 870... Loss: 1.5686... Val Loss: 1.5602\n",
      "Epoch: 7/20... Step: 880... Loss: 1.5680... Val Loss: 1.5564\n",
      "Epoch: 7/20... Step: 890... Loss: 1.5648... Val Loss: 1.5542\n",
      "Epoch: 7/20... Step: 900... Loss: 1.5420... Val Loss: 1.5538\n",
      "Epoch: 7/20... Step: 910... Loss: 1.5168... Val Loss: 1.5441\n",
      "Epoch: 7/20... Step: 920... Loss: 1.5453... Val Loss: 1.5433\n",
      "Epoch: 7/20... Step: 930... Loss: 1.5251... Val Loss: 1.5358\n",
      "Epoch: 7/20... Step: 940... Loss: 1.5285... Val Loss: 1.5366\n",
      "Epoch: 7/20... Step: 950... Loss: 1.5434... Val Loss: 1.5326\n",
      "Epoch: 7/20... Step: 960... Loss: 1.5437... Val Loss: 1.5287\n",
      "Epoch: 7/20... Step: 970... Loss: 1.5459... Val Loss: 1.5217\n",
      "Epoch: 8/20... Step: 980... Loss: 1.5211... Val Loss: 1.5186\n",
      "Epoch: 8/20... Step: 990... Loss: 1.5184... Val Loss: 1.5164\n",
      "Epoch: 8/20... Step: 1000... Loss: 1.5097... Val Loss: 1.5082\n",
      "Epoch: 8/20... Step: 1010... Loss: 1.5410... Val Loss: 1.5086\n",
      "Epoch: 8/20... Step: 1020... Loss: 1.5125... Val Loss: 1.5026\n",
      "Epoch: 8/20... Step: 1030... Loss: 1.4988... Val Loss: 1.4996\n",
      "Epoch: 8/20... Step: 1040... Loss: 1.5043... Val Loss: 1.5033\n",
      "Epoch: 8/20... Step: 1050... Loss: 1.4848... Val Loss: 1.4954\n",
      "Epoch: 8/20... Step: 1060... Loss: 1.4861... Val Loss: 1.4923\n",
      "Epoch: 8/20... Step: 1070... Loss: 1.4958... Val Loss: 1.4941\n",
      "Epoch: 8/20... Step: 1080... Loss: 1.4957... Val Loss: 1.4882\n",
      "Epoch: 8/20... Step: 1090... Loss: 1.4722... Val Loss: 1.4791\n",
      "Epoch: 8/20... Step: 1100... Loss: 1.4692... Val Loss: 1.4799\n",
      "Epoch: 8/20... Step: 1110... Loss: 1.4752... Val Loss: 1.4755\n",
      "Epoch: 9/20... Step: 1120... Loss: 1.4792... Val Loss: 1.4750\n",
      "Epoch: 9/20... Step: 1130... Loss: 1.4848... Val Loss: 1.4703\n",
      "Epoch: 9/20... Step: 1140... Loss: 1.4717... Val Loss: 1.4655\n",
      "Epoch: 9/20... Step: 1150... Loss: 1.4931... Val Loss: 1.4652\n",
      "Epoch: 9/20... Step: 1160... Loss: 1.4497... Val Loss: 1.4602\n",
      "Epoch: 9/20... Step: 1170... Loss: 1.4571... Val Loss: 1.4583\n",
      "Epoch: 9/20... Step: 1180... Loss: 1.4557... Val Loss: 1.4589\n",
      "Epoch: 9/20... Step: 1190... Loss: 1.4896... Val Loss: 1.4579\n",
      "Epoch: 9/20... Step: 1200... Loss: 1.4311... Val Loss: 1.4534\n",
      "Epoch: 9/20... Step: 1210... Loss: 1.4473... Val Loss: 1.4495\n",
      "Epoch: 9/20... Step: 1220... Loss: 1.4417... Val Loss: 1.4492\n",
      "Epoch: 9/20... Step: 1230... Loss: 1.4249... Val Loss: 1.4465\n",
      "Epoch: 9/20... Step: 1240... Loss: 1.4250... Val Loss: 1.4401\n",
      "Epoch: 9/20... Step: 1250... Loss: 1.4436... Val Loss: 1.4382\n",
      "Epoch: 10/20... Step: 1260... Loss: 1.4358... Val Loss: 1.4397\n",
      "Epoch: 10/20... Step: 1270... Loss: 1.4309... Val Loss: 1.4373\n",
      "Epoch: 10/20... Step: 1280... Loss: 1.4454... Val Loss: 1.4301\n",
      "Epoch: 10/20... Step: 1290... Loss: 1.4333... Val Loss: 1.4335\n",
      "Epoch: 10/20... Step: 1300... Loss: 1.4125... Val Loss: 1.4277\n",
      "Epoch: 10/20... Step: 1310... Loss: 1.4224... Val Loss: 1.4257\n",
      "Epoch: 10/20... Step: 1320... Loss: 1.4038... Val Loss: 1.4261\n",
      "Epoch: 10/20... Step: 1330... Loss: 1.4071... Val Loss: 1.4225\n",
      "Epoch: 10/20... Step: 1340... Loss: 1.3914... Val Loss: 1.4176\n",
      "Epoch: 10/20... Step: 1350... Loss: 1.3861... Val Loss: 1.4114\n",
      "Epoch: 10/20... Step: 1360... Loss: 1.3903... Val Loss: 1.4140\n",
      "Epoch: 10/20... Step: 1370... Loss: 1.3765... Val Loss: 1.4150\n",
      "Epoch: 10/20... Step: 1380... Loss: 1.4253... Val Loss: 1.4040\n",
      "Epoch: 10/20... Step: 1390... Loss: 1.4171... Val Loss: 1.4064\n",
      "Epoch: 11/20... Step: 1400... Loss: 1.4243... Val Loss: 1.4086\n",
      "Epoch: 11/20... Step: 1410... Loss: 1.4353... Val Loss: 1.4024\n",
      "Epoch: 11/20... Step: 1420... Loss: 1.4159... Val Loss: 1.3960\n",
      "Epoch: 11/20... Step: 1430... Loss: 1.3856... Val Loss: 1.3972\n",
      "Epoch: 11/20... Step: 1440... Loss: 1.4157... Val Loss: 1.3942\n",
      "Epoch: 11/20... Step: 1450... Loss: 1.3465... Val Loss: 1.3934\n",
      "Epoch: 11/20... Step: 1460... Loss: 1.3613... Val Loss: 1.3937\n",
      "Epoch: 11/20... Step: 1470... Loss: 1.3589... Val Loss: 1.3924\n",
      "Epoch: 11/20... Step: 1480... Loss: 1.3742... Val Loss: 1.3834\n",
      "Epoch: 11/20... Step: 1490... Loss: 1.3724... Val Loss: 1.3864\n",
      "Epoch: 11/20... Step: 1500... Loss: 1.3598... Val Loss: 1.3864\n",
      "Epoch: 11/20... Step: 1510... Loss: 1.3407... Val Loss: 1.3836\n",
      "Epoch: 11/20... Step: 1520... Loss: 1.3835... Val Loss: 1.3824\n",
      "Epoch: 12/20... Step: 1530... Loss: 1.4456... Val Loss: 1.3782\n",
      "Epoch: 12/20... Step: 1540... Loss: 1.3863... Val Loss: 1.3744\n",
      "Epoch: 12/20... Step: 1550... Loss: 1.3828... Val Loss: 1.3719\n",
      "Epoch: 12/20... Step: 1560... Loss: 1.3860... Val Loss: 1.3770\n",
      "Epoch: 12/20... Step: 1570... Loss: 1.3353... Val Loss: 1.3745\n",
      "Epoch: 12/20... Step: 1580... Loss: 1.3175... Val Loss: 1.3704\n",
      "Epoch: 12/20... Step: 1590... Loss: 1.3164... Val Loss: 1.3728\n",
      "Epoch: 12/20... Step: 1600... Loss: 1.3397... Val Loss: 1.3674\n",
      "Epoch: 12/20... Step: 1610... Loss: 1.3292... Val Loss: 1.3634\n",
      "Epoch: 12/20... Step: 1620... Loss: 1.3333... Val Loss: 1.3626\n",
      "Epoch: 12/20... Step: 1630... Loss: 1.3601... Val Loss: 1.3583\n",
      "Epoch: 12/20... Step: 1640... Loss: 1.3279... Val Loss: 1.3639\n",
      "Epoch: 12/20... Step: 1650... Loss: 1.3093... Val Loss: 1.3623\n",
      "Epoch: 12/20... Step: 1660... Loss: 1.3608... Val Loss: 1.3554\n",
      "Epoch: 13/20... Step: 1670... Loss: 1.3269... Val Loss: 1.3604\n",
      "Epoch: 13/20... Step: 1680... Loss: 1.3416... Val Loss: 1.3544\n",
      "Epoch: 13/20... Step: 1690... Loss: 1.3194... Val Loss: 1.3521\n",
      "Epoch: 13/20... Step: 1700... Loss: 1.3202... Val Loss: 1.3594\n",
      "Epoch: 13/20... Step: 1710... Loss: 1.3062... Val Loss: 1.3545\n",
      "Epoch: 13/20... Step: 1720... Loss: 1.3077... Val Loss: 1.3535\n",
      "Epoch: 13/20... Step: 1730... Loss: 1.3502... Val Loss: 1.3542\n",
      "Epoch: 13/20... Step: 1740... Loss: 1.3066... Val Loss: 1.3499\n",
      "Epoch: 13/20... Step: 1750... Loss: 1.2824... Val Loss: 1.3544\n",
      "Epoch: 13/20... Step: 1760... Loss: 1.3055... Val Loss: 1.3461\n",
      "Epoch: 13/20... Step: 1770... Loss: 1.3337... Val Loss: 1.3443\n",
      "Epoch: 13/20... Step: 1780... Loss: 1.3011... Val Loss: 1.3468\n",
      "Epoch: 13/20... Step: 1790... Loss: 1.3015... Val Loss: 1.3520\n",
      "Epoch: 13/20... Step: 1800... Loss: 1.3251... Val Loss: 1.3411\n",
      "Epoch: 14/20... Step: 1810... Loss: 1.3197... Val Loss: 1.3436\n",
      "Epoch: 14/20... Step: 1820... Loss: 1.3044... Val Loss: 1.3366\n",
      "Epoch: 14/20... Step: 1830... Loss: 1.3193... Val Loss: 1.3358\n",
      "Epoch: 14/20... Step: 1840... Loss: 1.2763... Val Loss: 1.3359\n",
      "Epoch: 14/20... Step: 1850... Loss: 1.2462... Val Loss: 1.3372\n",
      "Epoch: 14/20... Step: 1860... Loss: 1.3169... Val Loss: 1.3384\n",
      "Epoch: 14/20... Step: 1870... Loss: 1.3160... Val Loss: 1.3431\n",
      "Epoch: 14/20... Step: 1880... Loss: 1.3166... Val Loss: 1.3321\n",
      "Epoch: 14/20... Step: 1890... Loss: 1.3294... Val Loss: 1.3352\n",
      "Epoch: 14/20... Step: 1900... Loss: 1.3103... Val Loss: 1.3292\n",
      "Epoch: 14/20... Step: 1910... Loss: 1.3016... Val Loss: 1.3271\n",
      "Epoch: 14/20... Step: 1920... Loss: 1.2979... Val Loss: 1.3293\n",
      "Epoch: 14/20... Step: 1930... Loss: 1.2675... Val Loss: 1.3276\n",
      "Epoch: 14/20... Step: 1940... Loss: 1.3236... Val Loss: 1.3300\n",
      "Epoch: 15/20... Step: 1950... Loss: 1.2849... Val Loss: 1.3384\n",
      "Epoch: 15/20... Step: 1960... Loss: 1.2965... Val Loss: 1.3278\n",
      "Epoch: 15/20... Step: 1970... Loss: 1.2770... Val Loss: 1.3290\n",
      "Epoch: 15/20... Step: 1980... Loss: 1.2830... Val Loss: 1.3311\n",
      "Epoch: 15/20... Step: 1990... Loss: 1.2761... Val Loss: 1.3230\n",
      "Epoch: 15/20... Step: 2000... Loss: 1.2582... Val Loss: 1.3204\n",
      "Epoch: 15/20... Step: 2010... Loss: 1.2878... Val Loss: 1.3221\n",
      "Epoch: 15/20... Step: 2020... Loss: 1.3004... Val Loss: 1.3219\n",
      "Epoch: 15/20... Step: 2030... Loss: 1.2708... Val Loss: 1.3261\n",
      "Epoch: 15/20... Step: 2040... Loss: 1.2848... Val Loss: 1.3190\n",
      "Epoch: 15/20... Step: 2050... Loss: 1.2614... Val Loss: 1.3170\n",
      "Epoch: 15/20... Step: 2060... Loss: 1.2701... Val Loss: 1.3209\n",
      "Epoch: 15/20... Step: 2070... Loss: 1.2892... Val Loss: 1.3134\n",
      "Epoch: 15/20... Step: 2080... Loss: 1.2694... Val Loss: 1.3191\n",
      "Epoch: 16/20... Step: 2090... Loss: 1.2872... Val Loss: 1.3213\n",
      "Epoch: 16/20... Step: 2100... Loss: 1.2697... Val Loss: 1.3171\n",
      "Epoch: 16/20... Step: 2110... Loss: 1.2620... Val Loss: 1.3130\n",
      "Epoch: 16/20... Step: 2120... Loss: 1.2673... Val Loss: 1.3130\n",
      "Epoch: 16/20... Step: 2130... Loss: 1.2444... Val Loss: 1.3094\n",
      "Epoch: 16/20... Step: 2140... Loss: 1.2512... Val Loss: 1.3132\n",
      "Epoch: 16/20... Step: 2150... Loss: 1.2781... Val Loss: 1.3097\n",
      "Epoch: 16/20... Step: 2160... Loss: 1.2568... Val Loss: 1.3123\n",
      "Epoch: 16/20... Step: 2170... Loss: 1.2586... Val Loss: 1.3069\n",
      "Epoch: 16/20... Step: 2180... Loss: 1.2392... Val Loss: 1.3074\n",
      "Epoch: 16/20... Step: 2190... Loss: 1.2828... Val Loss: 1.3105\n",
      "Epoch: 16/20... Step: 2200... Loss: 1.2465... Val Loss: 1.3039\n",
      "Epoch: 16/20... Step: 2210... Loss: 1.2155... Val Loss: 1.3058\n",
      "Epoch: 16/20... Step: 2220... Loss: 1.2670... Val Loss: 1.3024\n",
      "Epoch: 17/20... Step: 2230... Loss: 1.2412... Val Loss: 1.3121\n",
      "Epoch: 17/20... Step: 2240... Loss: 1.2435... Val Loss: 1.3038\n",
      "Epoch: 17/20... Step: 2250... Loss: 1.2243... Val Loss: 1.3043\n",
      "Epoch: 17/20... Step: 2260... Loss: 1.2378... Val Loss: 1.3024\n",
      "Epoch: 17/20... Step: 2270... Loss: 1.2523... Val Loss: 1.2964\n",
      "Epoch: 17/20... Step: 2280... Loss: 1.2603... Val Loss: 1.3004\n",
      "Epoch: 17/20... Step: 2290... Loss: 1.2646... Val Loss: 1.2992\n",
      "Epoch: 17/20... Step: 2300... Loss: 1.2201... Val Loss: 1.3002\n",
      "Epoch: 17/20... Step: 2310... Loss: 1.2358... Val Loss: 1.2966\n",
      "Epoch: 17/20... Step: 2320... Loss: 1.2364... Val Loss: 1.2950\n",
      "Epoch: 17/20... Step: 2330... Loss: 1.2388... Val Loss: 1.2956\n",
      "Epoch: 17/20... Step: 2340... Loss: 1.2541... Val Loss: 1.2945\n",
      "Epoch: 17/20... Step: 2350... Loss: 1.2497... Val Loss: 1.2942\n",
      "Epoch: 17/20... Step: 2360... Loss: 1.2511... Val Loss: 1.2979\n",
      "Epoch: 18/20... Step: 2370... Loss: 1.2270... Val Loss: 1.2947\n",
      "Epoch: 18/20... Step: 2380... Loss: 1.2292... Val Loss: 1.2912\n",
      "Epoch: 18/20... Step: 2390... Loss: 1.2288... Val Loss: 1.2920\n",
      "Epoch: 18/20... Step: 2400... Loss: 1.2526... Val Loss: 1.2906\n",
      "Epoch: 18/20... Step: 2410... Loss: 1.2518... Val Loss: 1.2930\n",
      "Epoch: 18/20... Step: 2420... Loss: 1.2266... Val Loss: 1.2944\n",
      "Epoch: 18/20... Step: 2430... Loss: 1.2386... Val Loss: 1.2914\n",
      "Epoch: 18/20... Step: 2440... Loss: 1.2274... Val Loss: 1.2950\n",
      "Epoch: 18/20... Step: 2450... Loss: 1.2224... Val Loss: 1.2910\n",
      "Epoch: 18/20... Step: 2460... Loss: 1.2366... Val Loss: 1.2860\n",
      "Epoch: 18/20... Step: 2470... Loss: 1.2358... Val Loss: 1.2898\n",
      "Epoch: 18/20... Step: 2480... Loss: 1.2178... Val Loss: 1.2868\n",
      "Epoch: 18/20... Step: 2490... Loss: 1.2218... Val Loss: 1.2907\n",
      "Epoch: 18/20... Step: 2500... Loss: 1.2179... Val Loss: 1.2881\n",
      "Epoch: 19/20... Step: 2510... Loss: 1.2207... Val Loss: 1.2899\n",
      "Epoch: 19/20... Step: 2520... Loss: 1.2331... Val Loss: 1.2863\n",
      "Epoch: 19/20... Step: 2530... Loss: 1.2392... Val Loss: 1.2856\n",
      "Epoch: 19/20... Step: 2540... Loss: 1.2456... Val Loss: 1.2827\n",
      "Epoch: 19/20... Step: 2550... Loss: 1.2138... Val Loss: 1.2839\n",
      "Epoch: 19/20... Step: 2560... Loss: 1.2258... Val Loss: 1.2797\n",
      "Epoch: 19/20... Step: 2570... Loss: 1.2114... Val Loss: 1.2831\n",
      "Epoch: 19/20... Step: 2580... Loss: 1.2524... Val Loss: 1.2841\n",
      "Epoch: 19/20... Step: 2590... Loss: 1.2142... Val Loss: 1.2844\n",
      "Epoch: 19/20... Step: 2600... Loss: 1.2170... Val Loss: 1.2797\n",
      "Epoch: 19/20... Step: 2610... Loss: 1.2147... Val Loss: 1.2805\n",
      "Epoch: 19/20... Step: 2620... Loss: 1.1934... Val Loss: 1.2801\n",
      "Epoch: 19/20... Step: 2630... Loss: 1.2116... Val Loss: 1.2817\n",
      "Epoch: 19/20... Step: 2640... Loss: 1.2195... Val Loss: 1.2793\n",
      "Epoch: 20/20... Step: 2650... Loss: 1.2226... Val Loss: 1.2797\n",
      "Epoch: 20/20... Step: 2660... Loss: 1.2262... Val Loss: 1.2762\n",
      "Epoch: 20/20... Step: 2670... Loss: 1.2216... Val Loss: 1.2768\n",
      "Epoch: 20/20... Step: 2680... Loss: 1.2275... Val Loss: 1.2784\n",
      "Epoch: 20/20... Step: 2690... Loss: 1.2142... Val Loss: 1.2794\n",
      "Epoch: 20/20... Step: 2700... Loss: 1.2172... Val Loss: 1.2777\n",
      "Epoch: 20/20... Step: 2710... Loss: 1.1939... Val Loss: 1.2751\n",
      "Epoch: 20/20... Step: 2720... Loss: 1.1976... Val Loss: 1.2782\n",
      "Epoch: 20/20... Step: 2730... Loss: 1.1914... Val Loss: 1.2788\n",
      "Epoch: 20/20... Step: 2740... Loss: 1.1917... Val Loss: 1.2700\n",
      "Epoch: 20/20... Step: 2750... Loss: 1.1903... Val Loss: 1.2728\n",
      "Epoch: 20/20... Step: 2760... Loss: 1.1818... Val Loss: 1.2770\n",
      "Epoch: 20/20... Step: 2770... Loss: 1.2199... Val Loss: 1.2728\n",
      "Epoch: 20/20... Step: 2780... Loss: 1.2367... Val Loss: 1.2800\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Checkpoint"
   ],
   "metadata": {
    "id": "4x3GSUSyK6XL",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# change the name, for saving multiple files\n",
    "model_name = 'rnn_20_epoch.net'\n",
    "\n",
    "checkpoint = {'n_hidden': net.n_hidden,\n",
    "              'n_layers': net.n_layers,\n",
    "              'state_dict': net.state_dict(),\n",
    "              'tokens': net.chars}\n",
    "\n",
    "with open(model_name, 'wb') as f:\n",
    "    torch.save(checkpoint, f)"
   ],
   "metadata": {
    "id": "H5kBGOugKlb-",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1658431054863,
     "user_tz": -120,
     "elapsed": 12,
     "user": {
      "displayName": "Mohamed Ashraf",
      "userId": "01470115126079514692"
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Making Predictions\n"
   ],
   "metadata": {
    "id": "eJN_PO7-Knmb",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def predict(net, char, h=None, top_k=None):\n",
    "        ''' Given a character, predict the next character.\n",
    "            Returns the predicted character and the hidden state.\n",
    "        '''\n",
    "        \n",
    "        # tensor inputs\n",
    "        x = np.array([[net.char2int[char]]])\n",
    "        x = one_hot_encode(x, len(net.chars))\n",
    "        inputs = torch.from_numpy(x)\n",
    "        \n",
    "        if(train_on_gpu):\n",
    "            inputs = inputs.cuda()\n",
    "        \n",
    "        # detach hidden state from history\n",
    "        h = tuple([each.data for each in h])\n",
    "        # get the output of the model\n",
    "        out, h = net(inputs, h)\n",
    "\n",
    "        # get the character probabilities\n",
    "        p = F.softmax(out, dim=1).data\n",
    "        if(train_on_gpu):\n",
    "            p = p.cpu() # move to cpu\n",
    "        \n",
    "        # get top characters\n",
    "        if top_k is None:\n",
    "            top_ch = np.arange(len(net.chars))\n",
    "        else:\n",
    "            p, top_ch = p.topk(top_k)\n",
    "            top_ch = top_ch.numpy().squeeze()\n",
    "        \n",
    "        # select the likely next character with some element of randomness\n",
    "        p = p.numpy().squeeze()\n",
    "        char = np.random.choice(top_ch, p=p/p.sum())\n",
    "        \n",
    "        # return the encoded value of the predicted char and the hidden state\n",
    "        return net.int2char[char], h"
   ],
   "metadata": {
    "id": "7M6YvFAHKpU7",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1658431054863,
     "user_tz": -120,
     "elapsed": 5,
     "user": {
      "displayName": "Mohamed Ashraf",
      "userId": "01470115126079514692"
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# generating text"
   ],
   "metadata": {
    "id": "Inhl2M0wKwEl",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def sample(net, size, prime='The', top_k=None):\n",
    "        \n",
    "    global char\n",
    "    if(train_on_gpu):\n",
    "        net.cuda()\n",
    "    else:\n",
    "        net.cpu()\n",
    "    \n",
    "    net.eval() # eval mode\n",
    "    \n",
    "    # First off, run through the prime characters\n",
    "    chars = [ch for ch in prime]\n",
    "    h = net.init_hidden(1)\n",
    "    for ch in prime:\n",
    "        char, h = predict(net, ch, h, top_k=top_k)\n",
    "\n",
    "    chars.append(char)\n",
    "    \n",
    "    # Now pass in the previous character and get a new one\n",
    "    for ii in range(size):\n",
    "        char, h = predict(net, chars[-1], h, top_k=top_k)\n",
    "        chars.append(char)\n",
    "\n",
    "    return ''.join(chars)"
   ],
   "metadata": {
    "id": "KEJt5de7KxOa",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1658431054864,
     "user_tz": -120,
     "elapsed": 5,
     "user": {
      "displayName": "Mohamed Ashraf",
      "userId": "01470115126079514692"
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(sample(net, 1000, prime='Anna', top_k=5))\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vOrV0_WrKy8y",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1658431055723,
     "user_tz": -120,
     "elapsed": 864,
     "user": {
      "displayName": "Mohamed Ashraf",
      "userId": "01470115126079514692"
     }
    },
    "outputId": "a9b1e055-bf57-4747-b9af-50faa3269b5f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anna, who was\n",
      "and for his face. But to say something about the mononce of his\n",
      "hind home, watched the cape, and almost taking his his wife, the\n",
      "prince.\n",
      "\n",
      "\"Yes, you're not letting it.\"\n",
      "\n",
      "\"Anna has so such a side--as I'll go awina and most asking only a life\n",
      "which I always begin to be done; and I don't call it, then you want\n",
      "all sometomenter, that it wants to say, that.... You must have\n",
      "been the same.\"\n",
      "\n",
      "The crush of this comparions had already set about him. But there were\n",
      "the fact would not cannot have been bound.\"\n",
      "\n",
      "At times, the soul they could not help have brother that it\n",
      "seemed to her, he saw the condution of the forest. He saw that\n",
      "seemed to him how the chears, to those wend with the propiritic of the step\n",
      "which he clutched his hands, and there will say to her heart, as had\n",
      "the study.\n",
      "\n",
      "\"That manners of some point of an instant, or the carriage as a\n",
      "solled crowd and sense, and that you were a strange.\"\n",
      "\n",
      "And was a smile, and to tell her a thought, but he had saw a condliant\n",
      "daughter and a pa\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Loading a checkpoint\n"
   ],
   "metadata": {
    "id": "ASxYnxT4K3Er",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Here we have loaded in a model that trained over 20 epochs `rnn_20_epoch.net`\n",
    "with open('rnn_20_epoch.net', 'rb') as f:\n",
    "    checkpoint = torch.load(f)\n",
    "    \n",
    "loaded = CharRNN(checkpoint['tokens'], n_hidden=checkpoint['n_hidden'], n_layers=checkpoint['n_layers'])\n",
    "loaded.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "# Sample using a loaded model\n",
    "print(sample(loaded, 2000, top_k=5, prime=\"And Levin said\"))\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z1iOLLKRK-ML",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1658431056908,
     "user_tz": -120,
     "elapsed": 1189,
     "user": {
      "displayName": "Mohamed Ashraf",
      "userId": "01470115126079514692"
     }
    },
    "outputId": "7b2aea58-6457-492d-be5d-4dc304969c01",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And Levin said\n",
      "such a minute.\n",
      "\n",
      "At that importance of the strange with his forest, all the common\n",
      "people showed without hurriedly and the position of the pronding house,\n",
      "their son, she went on women, before she felt her for the most\n",
      "childled and husing. He felt that this came out and to hold that\n",
      "starting to the carriage of his house, had been to be a soul of the\n",
      "single of the men, and with the children had been bound to anyone, and\n",
      "at the draw to her fire helpers, and the first part world and watch had\n",
      "been all his settened and his face. The same well as if they was an one\n",
      "of the moments and sincerely should give it to him to be done on all the\n",
      "door.\n",
      "\n",
      "\"Well, we shall go out.\"\n",
      "\n",
      "\"You devermonate my wife, and there would be a stair,\n",
      "and when she has a servant, but in this carriage is themselves. If you\n",
      "want to say something, but it's all so all three morning to him.\n",
      "And the painter of myself almust must stay for a secret most\n",
      "colonel.\"\n",
      "\n",
      "\"I don't know it with the marsh.\"\n",
      "\n",
      "\"I say to her, and that you shouldn't should be at the\n",
      "portrait. We shaulder it! I can't have been done,\" he said to her\n",
      "son, siling.\n",
      "\n",
      "\"I don't see it of all out, and to be delighted for you and the sacrisicy, it\n",
      "will have suddendy the carriage. We were so good-naturated to the\n",
      "children, we may some of his mistakes.\n",
      "A down of a man show him, that I have been taking off the\n",
      "room, she in the peasants was. And I had not been a matter in\n",
      "the same than there, and we want to that in the sun on her face....\n",
      "There has been an expression.\" Stepan Arkadyevitch could not see\n",
      "them, and the pensalip strings and chammen, and a little court\n",
      "of the peasants went to him and her fantiages, and a peach and half\n",
      "who were all that in the portrait were not been breaking at the\n",
      "childrons and the forest.\n",
      "\n",
      "\"I see how I went up too,\" Anna said to her and the portrait. \"What do\n",
      "you think? What answer there was in this, the priect of a peniture to\n",
      "see the same, and to say what hands. And so I can't see the\n",
      "painful are as a signing the chose set\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}